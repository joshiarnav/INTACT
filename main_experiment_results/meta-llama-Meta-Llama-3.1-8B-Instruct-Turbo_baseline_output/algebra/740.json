{
    "problem": "Jordan ran 2 miles in half the time it took Steve to run 3 miles. If it took Steve 24 minutes to run 3 miles, using the same rates, how many minutes would it take Jordan to run 5 miles?",
    "solution": "Since Steve's 3-mile time is 24 minutes, Jordan ran 2 miles in $\\frac{1}{2}\\cdot24=12$ minutes.  Therefore, each mile takes Jordan 6 minutes to run, so he would take $6\\cdot5=\\boxed{30}$ minutes to run five miles.",
    "total_tokens": 237,
    "time_taken": 3.6985480785369873,
    "file_name": "./MATH_subsample_uniform/algebra/740.json",
    "model_solution": "Since it took Steve 24 minutes to run 3 miles, we can find the time it took Steve to run 1 mile by dividing 24 by 3, which is 8 minutes per mile. \n\nGiven that it took Jordan half the time it took Steve to run 2 miles, and since Steve runs 1 mile in 8 minutes, Jordan runs 1 mile in 8 / 2, which equals 4 minutes per mile.\n\nTo find out how long it would take for Jordan to run 5 miles, we multiply the time it takes for Jordan to run 1 mile by 5, which is 4 * 5 = 20 minutes.\n\nTherefore, it would take Jordan 20 minutes to run 5 miles."
}